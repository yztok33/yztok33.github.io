![img](https://i.loli.net/2020/07/25/kDsNtjyovu1fq2a.png)

# SHAP：可解释机器学习库

[TOC]

## 1. 什么是Shaply值

SHAP值的主要思想就是Shapley值，Shapley值是一个来自合作博弈论（coalitional game theory）的方法，由Shapley在1953年创造的Shapley值是一种根据玩家对总支出的贡献来为玩家分配支出的方法，玩家在联盟中合作并从这种合作中获得一定的收益。用shaply值去解释机器学习的预测的话，其中“总支出”就是数据集单个实例的模型预测值，“玩家”是实例的特征值，“收益”是该实例的实际预测减去所有实例的平均预测。

### 1.1 抛出问题

为什么要进行模型解释？想象一下，信用卡公司使用随机森林建立了欺诈检测模型，该模型可将每一笔交易分类为有效交易或欺诈交易。如果将交易归类为欺诈后，分析师想要知道模型为何做出这决定，即该交易的什么特征对结果产生重大影响，该怎么办？

### 1.2 例子说明

我们知道，决策树做出的每个决策，都有从树的根到叶的一条路径，由一系列子决策组成，每个子决策都有助于最终的预测。Shaply值的输出过程类似于此，通过加总每个特征值下shaply值，从而输出最终结果。下图展示了基本原理。

![image-20200725201033196](https://i.loli.net/2020/07/25/XYI64aj5NwxvhMQ.png)

![image-20200725201153771](https://i.loli.net/2020/07/25/pJqdDCY2Ki8ANLT.png)

再举个例子，假设已经训练了一个机器学习模型来预测公寓价格，分别有park、size、floor、car四个特征。某个面积为50平方米（size=50）、位于二楼（floor=2nd）、附近有一个公园（park=nearby）、禁止猫咪（cat=banned）的公寓，它预测价格为300,000欧元，你需要解释这个预测，即每个特征是如何促进预测的？当所有公寓的平均预测为310,000欧元时，与平均预测相比，每个特征值对预测的贡献是多少？

![The predicted price for a 50 m^2^ 2nd floor apartment with a nearby park and cat ban is €300,000. Our goal is to explain how each of these feature values contributed to the prediction.](https://i.loli.net/2020/07/25/aBDt5UvEYVqZeG7.png)

在我们的公寓示例中，park=nearby，cat=banned，size=50，floor=2nd的特征值共同实现了300,000欧元的预测。我们的目标是解释实际预测（300,000欧元）和平均预测（310,000欧元）之间的差异：-10,000欧元。答案可能是：park=nearby贡献了30,000欧元，size=50贡献了10,000欧元，floor=2nd贡献了0欧元，cat=banned贡献了-50,000欧元，这些贡献加起来为-10,000欧元，即最终预测减去平均预测的公寓价格。

**那实际上我们应该如何计算目标公寓实例（park=nearby，cat=banned，size=50，floor=2nd）其中一个特征的Shapley值？**

**Shapley值是所有可能联盟中特征值的平均边际贡献**。以该公寓实例的cat=banned为例，在下图中，我们估计了cat=banned特征值被添加到park=nearby和size=50的联盟后的贡献。第一步，我们从数据中随机抽取另一个公寓（该公寓floor=1st，cat=allowed，park和size可以不关注），使用该公寓自己的floor特征值1st，模拟出park=nearby，size=50和cat=banned的联盟，然后我们用这个组合（floor=1st，park=nearby，size=50和cat=banned）预测公寓的价格为310,000欧元。第二步，我们从联盟中删除cat=banned，然后用该公寓的cat特征值allowed替代，我们用这个组合（floor=1st，park=nearby，size=50和cat=allowed）预测公寓的价格为320,000欧元。

![One sample repetition to estimate the contribution of `cat-banned` to the prediction when added to the coalition of `park-nearby` and `area-50`.](https://i.loli.net/2020/07/25/g9hnzfFUliPmwo6.png)

可以看到，基于我们随机抽取的公寓，我们预测park=nearby，size=50和cat=banned的联盟的公寓价格为310,000欧元，预测park=nearby和size=50的联盟的公寓价格为320,000欧元，那cat=banned的贡献是310,000欧元 - 320,000欧元 = -10,000欧元，由于该公寓充当cat和floor特征值的“贡献者（donor）”，所以这个估计值取决于随机抽取的公寓的值，如果我们重复这个抽样步骤并取贡献的平均，我们将得到更好的估计。

上面只介绍了park=nearby和size=50联盟的贡献，而Shapley值时所有可能联盟的所有边际贡献的平均值，所以我们应该对所有可能的联盟重复这个计算。计算时间随着特征的数量和每个联盟中抽样的实例数量呈指数增长。下面是计算目标公寓的cat=banned的Shapley值的所有特征值联盟：

- 空联盟
- park=nearby
- size=50
- floor=2nd
- park=nearby 和 size=50
- park=nearby 和 floor=2nd
- size=50 和floor=2nd
- park=nearby 和size=50 和floor=2nd.

对于这些联盟中的每一个，我们计算带有和不带有cat=banned特征值的预测公寓价格，并计算差值来获得边际贡献，Shapley值是边际贡献的（加权）平均值，我们用来自数据集的随机公寓的特征值替换不在联盟中的特征的特征值，以从机器学习模型获得预测。如果我们估计所有特征值的Shapley值，我们将得到特征值中预测的完整分布（减去平均值）。

### 1.3 公式说明（直接上图）

![image-20200725204945150](https://i.loli.net/2020/07/25/278laZXYb4JxP3G.png)

![image-20200725205019622](https://i.loli.net/2020/07/25/a1R7Y4d5st3u8zW.png)

![image-20200725205617915](https://i.loli.net/2020/07/25/5xsknX2tSMGrZag.png)

### 1.4 估计Shaply值

![image-20200725205738318](https://i.loli.net/2020/07/25/CqlgvAktyNVTPeS.png)

![image-20200725205326055](https://i.loli.net/2020/07/25/6CrVDQbjuxHzqTU.png)

![image-20200725205345579](https://i.loli.net/2020/07/25/8aNnIYqsfSJC1LR.png)

## 2. SHAP原理（后续补充）

SHAP（SHapley Additive exPlanations）的应用方向有很多，比如TreeExplainer、DeepExplainer、GradientExplainer、KernelExplainer，本文只对TreeExplainer进行说明，TreeExplainer是Tree SHAP的实现，是基于树模型的一种估计方法。

### 2.1 SHAP公式

### 2.2 计算SHAP值

### 2.3 TREE SHAP

## 3. SHAP使用

### 3.1 SHAP值的一致性

定义**一致性：每当我们更改模型以使其更依赖于某个特征时，该特征的归因重要性不应该降低**。如果一致性不成立，意味着当一个模型被更改为某个特征对模型输出的影响更大时，反而会降低该特征的重要性，那么我们不能比较任意两个模型之间的归因重要性，因为具有较高分配归因的特征并不意味着模型实际上更依赖该特征。

### 3.2 预测值可视化

Python的shap包带来了一种可视化：可以将Shapley值等特性属性可视化为“力”，每个特征值都是一个增加或减少预测的力。预测从基线开始，基线是所有预测的平均值，每个Shapley值是一个箭头，增加（正值）或减少（负值）预测。

集成树解释单个样本

```python
import xgboost
import shap

# load JS visualization code to notebook
shap.initjs()

# train XGBoost model
X,y = shap.datasets.boston()
model = xgboost.train({"learning_rate": 0.01}, xgboost.DMatrix(X, label=y), 100)

# explain the model's predictions using SHAP
# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)

# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)
shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])
```

[![img](https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_instance.png)](https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_instance.png)

该图基于波士顿房价数据集，本条样本可视化图显示，LSTAT = 4.98 促进了预测房价的上升；而蓝色RM=6.575 抑制预测房价的上升，且它们都是各自阵营最重要的因素。

### 3.3 SHAP特征重要度

SHAP特征重要度背后的想法很简单：具有较大Shapley绝对值的特征很重要。由于我们需要全局重要度，因此我们在数据中对每个特征的Shapley绝对值取平均值：

![](https://i.loli.net/2020/08/20/lAZS2e53Wxpy1Y9.png)

我们还可以仅取每个特征的SHAP值的平均绝对值来获得标准条形图（产生用于多类输出的堆叠条形图）:

```python
shap.summary_plot(shap_values, X, plot_type="bar")
```

[![img](https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot_bar.png)](https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot_bar.png)

### 3.4 SHAP摘要图

摘要图结合了特征重要度和特征的影响。摘要图上的每个点都是一个特征和一个实例的Shapley值，y轴上的位置由特征决定，x轴上的位置由Shapley值决定，颜色代表特征值从小到大，重叠点在y轴方向上抖动，因此我们可以了解每个特征的Shapley值的分布。

为了概述哪些特征对于模型最重要，我们可以绘制每个样本的每个特征的SHAP值。下图通过所有样本上SHAP值幅度的总和对要素进行排序，并使用SHAP值显示每个要素对模型输出的影响分布。颜色代表特征值（红色高，蓝色低）。例如，这表明较高的LSTAT（较低的人口状况）会降低预测的房价。

```python
# summarize the effects of all the features
shap.summary_plot(shap_values, X)
```

![img](https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot.png)

### 3.5 SHAP交互值

SHAP交互值是SHAP值到更高阶交互的方法--shap.TreeExplainer(model).shap_interaction_values(X)。它将为每个预测返回一个矩阵，其中主要影响在对角线上，而交互作用则不在对角线上。这些值通常揭示出有趣的隐秘关系，例如，60岁男性死亡风险的增加如何达到峰值.

[![img](https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/nhanes_age_sex_interaction.png)](https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/nhanes_age_sex_interaction.png)

## 4.实例演示

下面以泰坦尼克号数据集为例，利用shap包输出一个样本的最重要的top3特征以及取值，满足生产上要求的解释性

 ```python
import shap
shap.initjs()  # notebook环境下，加载用于可视化的JS代码
 ```

```python
explainer = shap.TreeExplainer(clf)  # clf 已经训练好的分类器
result_matrix = explainer.shap_values(train[feats]) # shap值矩阵
shap.force_plot(explainer.expected_value, result_matrix[0,:], train[feats].iloc[0,:])
```

![image-20200821000819995](https://i.loli.net/2020/08/21/qfjLruveZV8KBi1.png)

```python
d_list=[]
for key, value in train[feats].iloc[880,:][np.argsort(result_matrix[880,:])][-3:].items():
    d = key + '=' +str(value)
    d_list.insert(0,d)
```

![image-20200821000900812](https://i.loli.net/2020/08/21/tS4lHUNKhmqsnBp.png)

符合图上的预期结果，这样就可以解释每个样本的前三个重要特征对应的特征值的情况了。



参考：

https://christophm.github.io/interpretable-ml-book/shapley.html

https://zhuanlan.zhihu.com/p/85791430

https://zhuanlan.zhihu.com/p/83412330

https://github.com/slundberg/shap